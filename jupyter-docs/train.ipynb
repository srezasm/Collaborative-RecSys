{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from settings import *\n",
    "from utils import load_np_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "dev = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using {dev} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative filtering model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|General <br />  Notation  | Description                                                                | Python (if any) |\n",
    "|:-------------------------|:---------------------------------------------------------------------------|-----------------|\n",
    "| $r(i,j)$                 | scalar; = 1  if user j rated movie i  = 0  otherwise                       |                 |\n",
    "| $y(i,j)$                 | scalar; = rating given by user j on movie  i    (if r(i,j) = 1 is defined) |                 |\n",
    "| $\\mathbf{w}^{(j)}$       | vector; parameters for user j                                              |                 |\n",
    "| $b^{(j)}$                | scalar; parameter for user j                                               |                 |\n",
    "| $\\mathbf{x}^{(i)}$       | vector; feature ratings for movie i                                        |                 |     \n",
    "| $n_m$                    | number of movies                                                           | num_movies      |\n",
    "| $n_u$                    | number of users                                                            | num_users       |\n",
    "| $n$                      | number of features                                                         | num_features    |\n",
    "| $\\mathbf{X}$             | matrix of vectors $\\mathbf{x}^{(i)}$                                       | X               |\n",
    "| $\\mathbf{W}$             | matrix of vectors $\\mathbf{w}^{(j)}$                                       | W               |\n",
    "| $\\mathbf{b}$             | vector of bias parameters $b^{(j)}$                                        | b               |\n",
    "| $\\mathbf{R}$             | matrix of elements $r(i,j)$                                                | R               |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collaborative filtering cost function is given by\n",
    "$$J({\\mathbf{x}^{(0)},...,\\mathbf{x}^{(n_m-1)},\\mathbf{w}^{(0)},b^{(0)},...,\\mathbf{w}^{(n_u-1)},b^{(n_u-1)}})= \\left[ \\frac{1}{2}\\sum_{(i,j):r(i,j)=1}(\\mathbf{w}^{(j)} \\cdot \\mathbf{x}^{(i)} + b^{(j)} - y^{(i,j)})^2 \\right]\n",
    "+ \\underbrace{\\left[\n",
    "\\frac{\\lambda}{2}\n",
    "\\sum_{j=0}^{n_u-1}\\sum_{k=0}^{n-1}(\\mathbf{w}^{(j)}_k)^2\n",
    "+ \\frac{\\lambda}{2}\\sum_{i=0}^{n_m-1}\\sum_{k=0}^{n-1}(\\mathbf{x}_k^{(i)})^2\n",
    "\\right]}_{regularization}\n",
    "\\tag{1}$$\n",
    "The first summation in (1) is \"for all $i$, $j$ where $r(i,j)$ equals $1$\" and could be written:\n",
    "\n",
    "$$\n",
    "= \\left[ \\frac{1}{2}\\sum_{j=0}^{n_u-1} \\sum_{i=0}^{n_m-1}r(i,j)*(\\mathbf{w}^{(j)} \\cdot \\mathbf{x}^{(i)} + b^{(j)} - y^{(i,j)})^2 \\right]\n",
    "+\\text{regularization}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoFil(nn.Module):\n",
    "    def __init__(self, num_movies: int, num_users: int, num_features: int) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # Add parameters\n",
    "        self.X = nn.Parameter(\n",
    "            torch.Tensor(num_movies, num_features).to(dev),\n",
    "        )\n",
    "        self.W = nn.Parameter(\n",
    "            torch.Tensor(num_users, num_features).to(dev),\n",
    "        )\n",
    "        self.b = nn.Parameter(\n",
    "            torch.Tensor(num_movies, 1).to(dev),\n",
    "        )\n",
    "\n",
    "        # Initialize parameters\n",
    "        nn.init.kaiming_uniform_(self.X, a=math.sqrt(5)).to(dev)\n",
    "        nn.init.kaiming_uniform_(self.W, a=math.sqrt(5)).to(dev)\n",
    "        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.W)\n",
    "        bound = 1 / math.sqrt(fan_in)\n",
    "        nn.init.uniform_(self.b, -bound, bound).to(dev)\n",
    "\n",
    "    def forward(self, R: torch.Tensor):\n",
    "    # def forward(self, R: torch.Tensor, Y: torch.Tensor, lambda_: float):\n",
    "        z = torch.matmul(self.X, self.W.T)\n",
    "        z = z.add(self.b)\n",
    "        return z.multiply(R)\n",
    "        # j = torch.matmul(self.X, self.W.T)\n",
    "        # j = j.add(self.b)\n",
    "        # j = j.subtract(Y)\n",
    "        # j = j.pow(2)\n",
    "        # j = j.multiply(R)\n",
    "        # j = j.multiply(0.5)\n",
    "        # return j.sum((self.W.pow(2).sum() + self.X.pow(2).sum()).multiply(lambda_ / 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CoFilLoss(y_pred: torch.Tensor,\n",
    "              state_dict=dict[str, torch.Tensor],\n",
    "              lambda_: float = 1):\n",
    "    j = y_pred.subtract(y_pred)\n",
    "    j = j.pow(2)\n",
    "    j = j.multiply(0.5)\n",
    "    j = j.sum()\n",
    "\n",
    "    W = state_dict['W']\n",
    "    X = state_dict['X']\n",
    "    return j + (W.pow(2).sum() + X.pow(2).sum()).multiply(lambda_ / 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and convert the data into tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = load_np_arr(Y_FILE_NAME)\n",
    "R = load_np_arr(R_FILE_NAME)\n",
    "\n",
    "Y = torch.tensor(Y, device=dev)\n",
    "R = torch.tensor(R, device=dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loaded data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. features: 10    i.e. num. of ratings\n",
      "Num. movies:   9724\n",
      "Num. users:    610\n"
     ]
    }
   ],
   "source": [
    "print('Num. features:', 10, '   i.e. num. of ratings')\n",
    "print('Num. movies:  ', R.shape[0])\n",
    "print('Num. users:   ', R.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train and sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R & Y shape:              torch.Size([9724, 610])\n",
      "R_train & Y_train shape:  torch.Size([7779, 610])\n",
      "R_test & Y_test shape:    torch.Size([1945, 610])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "R_train, R_test, Y_train, Y_test = train_test_split(R, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "print('R & Y shape:             ', R.shape)\n",
    "print('R_train & Y_train shape: ', R_train.shape)\n",
    "print('R_test & Y_test shape:   ', R_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CoFil(*R_train.shape, num_features=10).to(dev)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1398.1997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1398.1997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1398.1997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1398.1997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1398.1997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1398.1997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1398.1997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1398.1997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1398.1997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1398.1997, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    y_pred = model(R_train)\n",
    "\n",
    "    loss = CoFilLoss(y_pred, model.state_dict())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
